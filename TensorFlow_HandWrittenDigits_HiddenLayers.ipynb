{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "for k in range(12):\n",
    "    plt.subplot(3, 4, k+1)\n",
    "    plt.imshow(X_train[k], cmap = 'Greys')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784).astype('float32')\n",
    "X_test = X_test.reshape(10000, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the values(pixel) in range 0 to 1\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
       "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
       "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
       "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
       "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
       "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
       "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
       "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
       "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
       "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
       "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
       "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_test = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the Nueral Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Hidden Layers\n",
    "model.add(Dense(64, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "\n",
    "#Output Layers\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Classification type Problems Cross Entropy is the best kind of loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.8682 - val_loss: 0.2520 - val_accuracy: 0.9283\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2194 - accuracy: 0.9349 - val_loss: 0.1899 - val_accuracy: 0.9442\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1718 - accuracy: 0.9504 - val_loss: 0.1522 - val_accuracy: 0.9553\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1438 - accuracy: 0.9583 - val_loss: 0.1380 - val_accuracy: 0.9575\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1239 - accuracy: 0.9638 - val_loss: 0.1183 - val_accuracy: 0.9648\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1080 - accuracy: 0.9686 - val_loss: 0.1131 - val_accuracy: 0.9651\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9710 - val_loss: 0.1064 - val_accuracy: 0.9678\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0873 - accuracy: 0.9736 - val_loss: 0.1070 - val_accuracy: 0.9678\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.0966 - val_accuracy: 0.9708\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0716 - accuracy: 0.9787 - val_loss: 0.0959 - val_accuracy: 0.9720\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0653 - accuracy: 0.9806 - val_loss: 0.0961 - val_accuracy: 0.9700\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0601 - accuracy: 0.9821 - val_loss: 0.0919 - val_accuracy: 0.9721\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0557 - accuracy: 0.9834 - val_loss: 0.0838 - val_accuracy: 0.9746\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0514 - accuracy: 0.9847 - val_loss: 0.0834 - val_accuracy: 0.9741\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0478 - accuracy: 0.9859 - val_loss: 0.0886 - val_accuracy: 0.9722\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0441 - accuracy: 0.9872 - val_loss: 0.0826 - val_accuracy: 0.9743\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0414 - accuracy: 0.9878 - val_loss: 0.0864 - val_accuracy: 0.9742\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 0.0973 - val_accuracy: 0.9701\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0352 - accuracy: 0.9901 - val_loss: 0.0886 - val_accuracy: 0.9735\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.1062 - val_accuracy: 0.9687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a254686588>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we need to check the max accuracy based on the epochs so we get the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 716us/step - loss: 0.1062 - accuracy: 0.9687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10618449747562408, 0.9686999917030334]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = X_test[0].reshape(1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1091816e-07, 6.8081185e-09, 1.5716783e-05, 1.1854275e-05,\n",
       "        1.5900210e-09, 4.3943585e-10, 1.3209514e-14, 9.9997044e-01,\n",
       "        1.3113991e-07, 1.6346055e-06]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-a7ad347fdcb0>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
